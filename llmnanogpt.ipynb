{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.023702Z",
     "start_time": "2024-05-16T15:24:46.020638Z"
    }
   },
   "source": "print(\"hello world\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.029062Z",
     "start_time": "2024-05-16T15:24:46.026313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "  raw_training_data = f.read()\n",
    "\n",
    "print(len(raw_training_data))"
   ],
   "id": "5039825501f7ed79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.055803Z",
     "start_time": "2024-05-16T15:24:46.046314Z"
    }
   },
   "cell_type": "code",
   "source": "len(set(raw_training_data))",
   "id": "a8be3790674921fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.064714Z",
     "start_time": "2024-05-16T15:24:46.056719Z"
    }
   },
   "cell_type": "code",
   "source": "''.join(sorted(set(raw_training_data)))",
   "id": "26ebce1c0b136042",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.149263Z",
     "start_time": "2024-05-16T15:24:46.065593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "freqs = defaultdict(int)\n",
    "\n",
    "for letter in raw_training_data:\n",
    "  freqs[letter] += 1\n",
    "\n",
    "freqs"
   ],
   "id": "d381c57876ff54f7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'F': 1797,\n",
       "             'i': 45537,\n",
       "             'r': 48889,\n",
       "             's': 49696,\n",
       "             't': 67009,\n",
       "             ' ': 169892,\n",
       "             'C': 3820,\n",
       "             'z': 356,\n",
       "             'e': 94611,\n",
       "             'n': 48529,\n",
       "             ':': 10316,\n",
       "             '\\n': 40000,\n",
       "             'B': 2761,\n",
       "             'f': 15770,\n",
       "             'o': 65798,\n",
       "             'w': 17585,\n",
       "             'p': 10808,\n",
       "             'c': 15623,\n",
       "             'd': 31358,\n",
       "             'a': 55507,\n",
       "             'y': 20448,\n",
       "             'u': 26584,\n",
       "             'h': 51310,\n",
       "             ',': 19846,\n",
       "             'm': 22243,\n",
       "             'k': 7088,\n",
       "             '.': 7885,\n",
       "             'A': 7819,\n",
       "             'l': 33339,\n",
       "             'S': 4523,\n",
       "             'Y': 1718,\n",
       "             'v': 7793,\n",
       "             '?': 2462,\n",
       "             'R': 4869,\n",
       "             'M': 2840,\n",
       "             'W': 3530,\n",
       "             \"'\": 6187,\n",
       "             'L': 3876,\n",
       "             'I': 11832,\n",
       "             'N': 5079,\n",
       "             'g': 13356,\n",
       "             ';': 3628,\n",
       "             'b': 11321,\n",
       "             '!': 2172,\n",
       "             'O': 5481,\n",
       "             'j': 628,\n",
       "             'V': 798,\n",
       "             '-': 1897,\n",
       "             'T': 7015,\n",
       "             'H': 3068,\n",
       "             'E': 6041,\n",
       "             'U': 3313,\n",
       "             'D': 2089,\n",
       "             'P': 1641,\n",
       "             'q': 609,\n",
       "             'x': 529,\n",
       "             'J': 320,\n",
       "             'G': 2399,\n",
       "             'K': 1584,\n",
       "             'Q': 231,\n",
       "             '&': 3,\n",
       "             'Z': 198,\n",
       "             'X': 112,\n",
       "             '3': 27,\n",
       "             '$': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.151855Z",
     "start_time": "2024-05-16T15:24:46.149873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "SAMPLE_SIZE = 500\n",
    "training_data_size = len(raw_training_data)\n",
    "start = random.randrange(0, training_data_size - SAMPLE_SIZE)\n",
    "print(raw_training_data[start:start+SAMPLE_SIZE])"
   ],
   "id": "b36f404bd2c40ffd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ear with me; I am hungry for revenge,\n",
      "And now I cloy me with beholding it.\n",
      "Thy Edward he is dead, that stabb'd my Edward:\n",
      "Thy other Edward dead, to quit my Edward;\n",
      "Young York he is but boot, because both they\n",
      "Match not the high perfection of my loss:\n",
      "Thy Clarence he is dead that kill'd my Edward;\n",
      "And the beholders of this tragic play,\n",
      "The adulterate Hastings, Rivers, Vaughan, Grey,\n",
      "Untimely smother'd in their dusky graves.\n",
      "Richard yet lives, hell's black intelligencer,\n",
      "Only reserved their factor\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.160952Z",
     "start_time": "2024-05-16T15:24:46.153107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokens = ''.join(sorted(set(raw_training_data)))\n",
    "token_to_number = {t: i for i, t in enumerate(tokens)}\n",
    "token_to_number"
   ],
   "id": "69e8d2f4284ef3d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '$': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '3': 9,\n",
       " ':': 10,\n",
       " ';': 11,\n",
       " '?': 12,\n",
       " 'A': 13,\n",
       " 'B': 14,\n",
       " 'C': 15,\n",
       " 'D': 16,\n",
       " 'E': 17,\n",
       " 'F': 18,\n",
       " 'G': 19,\n",
       " 'H': 20,\n",
       " 'I': 21,\n",
       " 'J': 22,\n",
       " 'K': 23,\n",
       " 'L': 24,\n",
       " 'M': 25,\n",
       " 'N': 26,\n",
       " 'O': 27,\n",
       " 'P': 28,\n",
       " 'Q': 29,\n",
       " 'R': 30,\n",
       " 'S': 31,\n",
       " 'T': 32,\n",
       " 'U': 33,\n",
       " 'V': 34,\n",
       " 'W': 35,\n",
       " 'X': 36,\n",
       " 'Y': 37,\n",
       " 'Z': 38,\n",
       " 'a': 39,\n",
       " 'b': 40,\n",
       " 'c': 41,\n",
       " 'd': 42,\n",
       " 'e': 43,\n",
       " 'f': 44,\n",
       " 'g': 45,\n",
       " 'h': 46,\n",
       " 'i': 47,\n",
       " 'j': 48,\n",
       " 'k': 49,\n",
       " 'l': 50,\n",
       " 'm': 51,\n",
       " 'n': 52,\n",
       " 'o': 53,\n",
       " 'p': 54,\n",
       " 'q': 55,\n",
       " 'r': 56,\n",
       " 's': 57,\n",
       " 't': 58,\n",
       " 'u': 59,\n",
       " 'v': 60,\n",
       " 'w': 61,\n",
       " 'x': 62,\n",
       " 'y': 63,\n",
       " 'z': 64}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.164031Z",
     "start_time": "2024-05-16T15:24:46.161623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "number_to_token = {i: t for i, t in enumerate(tokens)}\n",
    "number_to_token"
   ],
   "id": "f9fc4f0a34d6c38e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\n',\n",
       " 1: ' ',\n",
       " 2: '!',\n",
       " 3: '$',\n",
       " 4: '&',\n",
       " 5: \"'\",\n",
       " 6: ',',\n",
       " 7: '-',\n",
       " 8: '.',\n",
       " 9: '3',\n",
       " 10: ':',\n",
       " 11: ';',\n",
       " 12: '?',\n",
       " 13: 'A',\n",
       " 14: 'B',\n",
       " 15: 'C',\n",
       " 16: 'D',\n",
       " 17: 'E',\n",
       " 18: 'F',\n",
       " 19: 'G',\n",
       " 20: 'H',\n",
       " 21: 'I',\n",
       " 22: 'J',\n",
       " 23: 'K',\n",
       " 24: 'L',\n",
       " 25: 'M',\n",
       " 26: 'N',\n",
       " 27: 'O',\n",
       " 28: 'P',\n",
       " 29: 'Q',\n",
       " 30: 'R',\n",
       " 31: 'S',\n",
       " 32: 'T',\n",
       " 33: 'U',\n",
       " 34: 'V',\n",
       " 35: 'W',\n",
       " 36: 'X',\n",
       " 37: 'Y',\n",
       " 38: 'Z',\n",
       " 39: 'a',\n",
       " 40: 'b',\n",
       " 41: 'c',\n",
       " 42: 'd',\n",
       " 43: 'e',\n",
       " 44: 'f',\n",
       " 45: 'g',\n",
       " 46: 'h',\n",
       " 47: 'i',\n",
       " 48: 'j',\n",
       " 49: 'k',\n",
       " 50: 'l',\n",
       " 51: 'm',\n",
       " 52: 'n',\n",
       " 53: 'o',\n",
       " 54: 'p',\n",
       " 55: 'q',\n",
       " 56: 'r',\n",
       " 57: 's',\n",
       " 58: 't',\n",
       " 59: 'u',\n",
       " 60: 'v',\n",
       " 61: 'w',\n",
       " 62: 'x',\n",
       " 63: 'y',\n",
       " 64: 'z'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.166636Z",
     "start_time": "2024-05-16T15:24:46.164470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode(s):\n",
    "  return_value = []\n",
    "  for character in s:\n",
    "    return_value.append(token_to_number[character])\n",
    "  return return_value\n",
    "\n",
    "encode(\"Tech Exchange\")"
   ],
   "id": "aa8e8ad75a88cab8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 43, 41, 46, 1, 17, 62, 41, 46, 39, 52, 45, 43]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.169084Z",
     "start_time": "2024-05-16T15:24:46.167133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decode(nums):\n",
    "  return ''.join([number_to_token[n] for n in nums])\n",
    "\n",
    "decode(encode(\"Tech Exchange\"))"
   ],
   "id": "2dd2497a0ddbbeab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tech Exchange'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.832061Z",
     "start_time": "2024-05-16T15:24:46.169541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# data = torch.tensor(encode(raw_training_data), dtype=torch.long)\n",
    "\n",
    "data = torch.tensor(encode(raw_training_data), dtype=torch.long)"
   ],
   "id": "1b453e0847999dd5",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.834690Z",
     "start_time": "2024-05-16T15:24:46.832796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "holdout_size = int(0.1 * len(data))\n",
    "holdout_size"
   ],
   "id": "df59f26d54122e0b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111539"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.838236Z",
     "start_time": "2024-05-16T15:24:46.836361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_data = data[:holdout_size]\n",
    "training_data = data[holdout_size:]\n",
    "len(test_data), len(training_data)"
   ],
   "id": "71ad98cbe63769d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111539, 1003855)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.841067Z",
     "start_time": "2024-05-16T15:24:46.838859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BLOCK_SIZE = 8\n",
    "training_data[:BLOCK_SIZE+1]"
   ],
   "id": "dc459ff88ff23428",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([43, 58,  6,  1, 25, 39, 56, 41, 47])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.843510Z",
     "start_time": "2024-05-16T15:24:46.841553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_from = random.randint(0, training_data_size-BLOCK_SIZE)\n",
    "decode(training_data[start_from:start_from+BLOCK_SIZE].tolist())"
   ],
   "id": "89fc6b8331cc572e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t days,\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.846124Z",
     "start_time": "2024-05-16T15:24:46.844046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random.seed(3434)\n",
    "start_from = random.randint(0, training_data_size-BLOCK_SIZE)\n",
    "decode(training_data[start_from:start_from+BLOCK_SIZE].tolist())"
   ],
   "id": "c4bc5547e3d5f715",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'like asi'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.849280Z",
     "start_time": "2024-05-16T15:24:46.846672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = training_data[:BLOCK_SIZE]\n",
    "y = training_data[1:BLOCK_SIZE+1]\n",
    "for t in range(BLOCK_SIZE):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'in: {context}, out: {target}')"
   ],
   "id": "31e2218bb8ed3a69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in: tensor([43]), out: 58\n",
      "in: tensor([43, 58]), out: 6\n",
      "in: tensor([43, 58,  6]), out: 1\n",
      "in: tensor([43, 58,  6,  1]), out: 25\n",
      "in: tensor([43, 58,  6,  1, 25]), out: 39\n",
      "in: tensor([43, 58,  6,  1, 25, 39]), out: 56\n",
      "in: tensor([43, 58,  6,  1, 25, 39, 56]), out: 41\n",
      "in: tensor([43, 58,  6,  1, 25, 39, 56, 41]), out: 47\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:46.852301Z",
     "start_time": "2024-05-16T15:24:46.849769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "BATCH_SIZE = 4"
   ],
   "id": "68d2456070a12159",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:31:36.086583Z",
     "start_time": "2024-05-16T15:31:36.081258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_batch(split):\n",
    "  data = training_data if split == 'train' else test_data\n",
    "  ix = torch.randint(len(data) - BLOCK_SIZE, (BATCH_SIZE,))\n",
    "  #print(ix)\n",
    "  x = torch.stack([data[i:i+BLOCK_SIZE] for i in ix])\n",
    "  y = torch.stack([data[i+1:i+BLOCK_SIZE+1] for i in ix])\n",
    "  return x, y\n",
    "\n",
    "get_batch('train')\n",
    "     "
   ],
   "id": "91dfa2001a541b99",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[46, 43,  1, 54, 56, 47, 57, 53],\n",
       "         [59, 45, 46, 47, 52, 45,  1, 47],\n",
       "         [61, 43,  1, 46, 43, 52, 41, 43],\n",
       "         [42, 61, 39, 56, 42,  6,  0, 13]]),\n",
       " tensor([[43,  1, 54, 56, 47, 57, 53, 52],\n",
       "         [45, 46, 47, 52, 45,  1, 47, 52],\n",
       "         [43,  1, 46, 43, 52, 41, 43,  1],\n",
       "         [61, 39, 56, 42,  6,  0, 13, 57]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:31:52.389726Z",
     "start_time": "2024-05-16T15:31:52.384791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xb, yb = get_batch('train')\n",
    "\n",
    "for b in range(BATCH_SIZE):\n",
    "  for t in range(BLOCK_SIZE):\n",
    "    context = xb[b, :t+1]\n",
    "    target = yb[b,t]\n",
    "    print(f'input {context.tolist()}, target {target}')"
   ],
   "id": "4c3f822c26672abb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input [52], target 53\n",
      "input [52, 53], target 58\n",
      "input [52, 53, 58], target 1\n",
      "input [52, 53, 58, 1], target 42\n",
      "input [52, 53, 58, 1, 42], target 53\n",
      "input [52, 53, 58, 1, 42, 53], target 5\n",
      "input [52, 53, 58, 1, 42, 53, 5], target 58\n",
      "input [52, 53, 58, 1, 42, 53, 5, 58], target 8\n",
      "input [1], target 35\n",
      "input [1, 35], target 43\n",
      "input [1, 35, 43], target 57\n",
      "input [1, 35, 43, 57], target 58\n",
      "input [1, 35, 43, 57, 58], target 51\n",
      "input [1, 35, 43, 57, 58, 51], target 53\n",
      "input [1, 35, 43, 57, 58, 51, 53], target 56\n",
      "input [1, 35, 43, 57, 58, 51, 53, 56], target 43\n",
      "input [39], target 56\n",
      "input [39, 56], target 58\n",
      "input [39, 56, 58], target 46\n",
      "input [39, 56, 58, 46], target 11\n",
      "input [39, 56, 58, 46, 11], target 0\n",
      "input [39, 56, 58, 46, 11, 0], target 28\n",
      "input [39, 56, 58, 46, 11, 0, 28], target 56\n",
      "input [39, 56, 58, 46, 11, 0, 28, 56], target 43\n",
      "input [63], target 43\n",
      "input [63, 43], target 56\n",
      "input [63, 43, 56], target 1\n",
      "input [63, 43, 56, 1], target 53\n",
      "input [63, 43, 56, 1, 53], target 59\n",
      "input [63, 43, 56, 1, 53, 59], target 45\n",
      "input [63, 43, 56, 1, 53, 59, 45], target 46\n",
      "input [63, 43, 56, 1, 53, 59, 45, 46], target 58\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T15:24:50.228319Z",
     "start_time": "2024-05-16T15:24:50.226028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ],
   "id": "27b74cda7afb7949",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T17:03:22.800876Z",
     "start_time": "2024-05-16T17:03:22.798540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 32\n",
    "BLOCK_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "MAX_ITERS = 5000\n",
    "EVAL_INTERVAL = 300\n",
    "EVAL_ITERS = 200\n",
    "NUM_EMBEDDINGS = 32"
   ],
   "id": "cb1b1a793ad371a2",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T16:46:48.186202Z",
     "start_time": "2024-05-16T16:46:48.146164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab_size = len(set(raw_training_data))\n",
    "\n",
    "class Head(nn.Module):\n",
    "  def __init__(self, head_size):\n",
    "    super().__init__()\n",
    "    self.key = nn.Linear(NUM_EMBEDDINGS, head_size, bias=False)\n",
    "    self.query = nn.Linear(NUM_EMBEDDINGS, head_size, bias=False)\n",
    "    self.value = nn.Linear(NUM_EMBEDDINGS, head_size, bias=False)\n",
    "    self.register_buffer('tril', torch.tril(torch.ones(BLOCK_SIZE, BLOCK_SIZE)))\n",
    "\n",
    "  def forward(self, x):\n",
    "    B,T,C = x.shape\n",
    "    k = self.key(x)\n",
    "    q = self.query(x)\n",
    "    wei = q @ k.transpose(-2, -1) * C**-0.5\n",
    "    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "    wei = F.softmax(wei, dim=-1)\n",
    "    v = self.value(x)\n",
    "    out = wei @ v\n",
    "    return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "  def __init__(self, vocab_size):\n",
    "    super().__init__()\n",
    "    self.token_embedding_table = nn.Embedding(vocab_size, NUM_EMBEDDINGS)\n",
    "    self.position_embedding_table = nn.Embedding(BLOCK_SIZE, NUM_EMBEDDINGS)\n",
    "    #self.sa_head = Head(NUM_EMBEDDINGS)\n",
    "    self.sa_heads = MultiHeadAttention(4, NUM_EMBEDDINGS//4)\n",
    "    self.lm_head = nn.Linear(NUM_EMBEDDINGS, vocab_size)\n",
    "\n",
    "\n",
    "  def forward(self, token, targets=None):\n",
    "    token_embeddings = self.token_embedding_table(token)\n",
    "    B, T = token.shape\n",
    "    position_embeddings = self.position_embedding_table(torch.arange(T))\n",
    "    x = token_embeddings + position_embeddings\n",
    "\n",
    "    x = self.sa_heads(x)\n",
    "    logits = self.lm_head(x)\n",
    "\n",
    "    if targets is None:\n",
    "      loss = None\n",
    "    else:\n",
    "      B, T, C = logits.shape\n",
    "      logits = logits.view(B*T, C)\n",
    "      targets = targets.view(B*T)\n",
    "      loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "    return logits, loss\n",
    "\n",
    "  def generate(self, idx, max_new_tokens):\n",
    "    for _ in range(max_new_tokens):\n",
    "      idx_cond = idx[:, -BLOCK_SIZE:]\n",
    "      logits, loss = self(idx_cond)\n",
    "      logits = logits[:, -1, :] # (B, C)\n",
    "      probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "      idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "      idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "z = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(z, 40)[0].tolist()))\n",
    "     "
   ],
   "id": "7c1095abcb5630fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x?vdKvEpMXON B.uDt-WMeOXlMe.wqjkk;ffNfGh\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T16:47:02.160846Z",
     "start_time": "2024-05-16T16:47:02.157018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "  out = {}\n",
    "  m.eval()\n",
    "  for split in ['train', 'val']:\n",
    "    losses = torch.zeros(EVAL_ITERS)\n",
    "    for k in range(EVAL_ITERS):\n",
    "      X, Y = get_batch(split)\n",
    "      logits, loss = m(X, Y)\n",
    "      losses[k] = loss.item()\n",
    "    out[split] = losses.mean()\n",
    "  m.train()\n",
    "  return out"
   ],
   "id": "ce2fe2c6a963f9d",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T16:47:45.476388Z",
     "start_time": "2024-05-16T16:47:21.854083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.Adam(m.parameters(), lr=1e-3)\n",
    "\n",
    "for iter in range(MAX_ITERS):\n",
    "\n",
    "  if iter % EVAL_INTERVAL == 0:\n",
    "    losses = estimate_loss()\n",
    "    print(f\"iter {iter}; train loss {losses['train']:.4f}; val loss {losses['val']:.4f}\")\n",
    "\n",
    "  xb, yb = get_batch('train')\n",
    "\n",
    "  logits, loss = m(xb, yb)\n",
    "  optimizer.zero_grad(set_to_none=True)\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ],
   "id": "6173ff7e706e0789",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0; train loss 4.2278; val loss 4.2309\n",
      "iter 300; train loss 2.8054; val loss 2.8098\n",
      "iter 600; train loss 2.6022; val loss 2.5881\n",
      "iter 900; train loss 2.5053; val loss 2.4983\n",
      "iter 1200; train loss 2.4609; val loss 2.4623\n",
      "iter 1500; train loss 2.4177; val loss 2.4298\n",
      "iter 1800; train loss 2.3950; val loss 2.4106\n",
      "iter 2100; train loss 2.3674; val loss 2.3906\n",
      "iter 2400; train loss 2.3538; val loss 2.3771\n",
      "iter 2700; train loss 2.3290; val loss 2.3524\n",
      "iter 3000; train loss 2.3150; val loss 2.3394\n",
      "iter 3300; train loss 2.3087; val loss 2.3504\n",
      "iter 3600; train loss 2.2898; val loss 2.3350\n",
      "iter 3900; train loss 2.2903; val loss 2.3105\n",
      "iter 4200; train loss 2.2718; val loss 2.3119\n",
      "iter 4500; train loss 2.2795; val loss 2.2974\n",
      "iter 4800; train loss 2.2575; val loss 2.2954\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T16:38:20.351359Z",
     "start_time": "2024-05-16T16:38:20.338296Z"
    }
   },
   "cell_type": "code",
   "source": "list(sorted(set(raw_training_data)))[25]",
   "id": "a63b24a120836dfc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T17:03:28.513631Z",
     "start_time": "2024-05-16T17:03:28.335911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "z = torch.zeros((1,1), dtype=torch.long)\n",
    "generated = m.generate(z, max_new_tokens=100000)\n",
    "generated_list = generated[0].tolist()\n",
    "print(decode(generated_list))"
   ],
   "id": "bcdba0190c93b4ec",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[56], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m z \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m), dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[0;32m----> 2\u001B[0m generated \u001B[38;5;241m=\u001B[39m \u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m generated_list \u001B[38;5;241m=\u001B[39m generated[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(decode(generated_list))\n",
      "Cell \u001B[0;32mIn[50], line 63\u001B[0m, in \u001B[0;36mBigramLanguageModel.generate\u001B[0;34m(self, idx, max_new_tokens)\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(max_new_tokens):\n\u001B[1;32m     62\u001B[0m   idx_cond \u001B[38;5;241m=\u001B[39m idx[:, \u001B[38;5;241m-\u001B[39mBLOCK_SIZE:]\n\u001B[0;32m---> 63\u001B[0m   logits, loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43midx_cond\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     64\u001B[0m   logits \u001B[38;5;241m=\u001B[39m logits[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :] \u001B[38;5;66;03m# (B, C)\u001B[39;00m\n\u001B[1;32m     65\u001B[0m   probs \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39msoftmax(logits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;66;03m# (B, C)\u001B[39;00m\n",
      "File \u001B[0;32m~/Developer/Let-em-cook/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/Let-em-cook/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[50], line 44\u001B[0m, in \u001B[0;36mBigramLanguageModel.forward\u001B[0;34m(self, token, targets)\u001B[0m\n\u001B[1;32m     42\u001B[0m token_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtoken_embedding_table(token)\n\u001B[1;32m     43\u001B[0m B, T \u001B[38;5;241m=\u001B[39m token\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m---> 44\u001B[0m position_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mposition_embedding_table\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marange\u001B[49m\u001B[43m(\u001B[49m\u001B[43mT\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m x \u001B[38;5;241m=\u001B[39m token_embeddings \u001B[38;5;241m+\u001B[39m position_embeddings\n\u001B[1;32m     47\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msa_heads(x)\n",
      "File \u001B[0;32m~/Developer/Let-em-cook/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/Let-em-cook/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Developer/Let-em-cook/.venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:163\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 163\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/Let-em-cook/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2264\u001B[0m, in \u001B[0;36membedding\u001B[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[1;32m   2258\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[1;32m   2259\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[1;32m   2260\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[1;32m   2261\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[1;32m   2262\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[1;32m   2263\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[0;32m-> 2264\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mIndexError\u001B[0m: index out of range in self"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T16:47:45.480152Z",
     "start_time": "2024-05-16T16:47:45.477372Z"
    }
   },
   "cell_type": "code",
   "source": "torch.tril(torch.ones(3,3))",
   "id": "e12d9f9fd7890fbd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e427e1789220d640"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
